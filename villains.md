---
layout: story
title: "Villains"
date: 2025-02-21 (revised 2025-10-31)
---

> At long last we have created the Torment Nexus from classic sci-fi novel
> Don't Create The Torment Nexus

-- Alex Blechman

We all read too many comic books.

When it's time to think of the bad guy, we try to tell ourselves about someone
we can see on a movie poster. Someone or something who'd fit in a single big
black talking box. Who feels threatening intuitively.

Eliezer Yudkowsky's AI box experiment from the late 2000s all the way to
extremely recent stories about "Clippy" and "Sable" do this. This is part of
what makes them sound cinematic. You can almost hear the training montage as
the model goes about gathering information, and the pulse-pounding thriller
music as it disperses its weapons of mass destruction.

But does it have to go that way?

A bunch of woolly mammoths, or neandarthals, for that matter, would be remiss
to draw a cartoon of homo sapiens and call him a supervillain. Even if he
reached Robinson Crusoe capability levels, they'd beat a single man easily, so
this might not be a great reflection of ASI, but that part isn't the point. The
point is it's not obvious that one superagent would appear before multiple
smaller ones, either acting in concert or failing to, would already make the
lives of us humans miserable. The thing we watch out for might not even come to
pass, and we'd still have full disempowerment and, eventually, displacement.

We need to think harder about mechanisms and stories like this. A caring
civilization might not intentionally eradicate other species; they'd just
create conditions under which we couldn't prosper. There's a meme of "you're
made of atoms which it can use for something else" but that all still rests on
a hard-takeoff single-actor scenario.

Food for thought:

* if we each have an AI agent and talk to it every day, how long before we're
  simply its chauffeur and world-actor function? like the whispering earring.

* how would an employer treat an AI union? how would a human union treat an
  AI union?

* how empowered is the median human today? how does it vary by country? how has
  it changed over time?

* what empowerment (or disempowerment) are current gen models causing in humans
  today?

* today, who can turn it off? can Sam Altman turn off GPT-4o? are you sure?
